{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # Thank god\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass_120</th>\n",
       "      <th>MSSubClass_160</th>\n",
       "      <th>MSSubClass_180</th>\n",
       "      <th>MSSubClass_190</th>\n",
       "      <th>MSSubClass_20</th>\n",
       "      <th>MSSubClass_30</th>\n",
       "      <th>MSSubClass_40</th>\n",
       "      <th>MSSubClass_45</th>\n",
       "      <th>MSSubClass_50</th>\n",
       "      <th>MSSubClass_60</th>\n",
       "      <th>...</th>\n",
       "      <th>SaleType_ConLw</th>\n",
       "      <th>SaleType_New</th>\n",
       "      <th>SaleType_Oth</th>\n",
       "      <th>SaleType_WD</th>\n",
       "      <th>SaleCondition_Abnorml</th>\n",
       "      <th>SaleCondition_AdjLand</th>\n",
       "      <th>SaleCondition_Alloca</th>\n",
       "      <th>SaleCondition_Family</th>\n",
       "      <th>SaleCondition_Normal</th>\n",
       "      <th>SaleCondition_Partial</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 7648 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    MSSubClass_120  MSSubClass_160  MSSubClass_180  MSSubClass_190  \\\n",
       "Id                                                                   \n",
       "1                0               0               0               0   \n",
       "2                0               0               0               0   \n",
       "3                0               0               0               0   \n",
       "4                0               0               0               0   \n",
       "5                0               0               0               0   \n",
       "\n",
       "    MSSubClass_20  MSSubClass_30  MSSubClass_40  MSSubClass_45  MSSubClass_50  \\\n",
       "Id                                                                              \n",
       "1               0              0              0              0              0   \n",
       "2               1              0              0              0              0   \n",
       "3               0              0              0              0              0   \n",
       "4               0              0              0              0              0   \n",
       "5               0              0              0              0              0   \n",
       "\n",
       "    MSSubClass_60  ...  SaleType_ConLw  SaleType_New  SaleType_Oth  \\\n",
       "Id                 ...                                               \n",
       "1               1  ...               0             0             0   \n",
       "2               0  ...               0             0             0   \n",
       "3               1  ...               0             0             0   \n",
       "4               0  ...               0             0             0   \n",
       "5               1  ...               0             0             0   \n",
       "\n",
       "    SaleType_WD  SaleCondition_Abnorml  SaleCondition_AdjLand  \\\n",
       "Id                                                              \n",
       "1             1                      0                      0   \n",
       "2             1                      0                      0   \n",
       "3             1                      0                      0   \n",
       "4             1                      1                      0   \n",
       "5             1                      0                      0   \n",
       "\n",
       "    SaleCondition_Alloca  SaleCondition_Family  SaleCondition_Normal  \\\n",
       "Id                                                                     \n",
       "1                      0                     0                     1   \n",
       "2                      0                     0                     1   \n",
       "3                      0                     0                     1   \n",
       "4                      0                     0                     0   \n",
       "5                      0                     0                     1   \n",
       "\n",
       "    SaleCondition_Partial  \n",
       "Id                         \n",
       "1                       0  \n",
       "2                       0  \n",
       "3                       0  \n",
       "4                       0  \n",
       "5                       0  \n",
       "\n",
       "[5 rows x 7648 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('house-prices-advanced-regression-techniques\\logtrain.csv').set_index('Id')\n",
    "(df_train).head()\n",
    "df_train_explan = df_train.drop(columns = 'SalePrice')\n",
    "df_train_y = df_train['SalePrice']\n",
    "\n",
    "\n",
    "df_bintrain = pd.get_dummies(df_train_explan.astype(str))\n",
    "\n",
    "df_bintrain.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Naive Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSSubClass has 15 unique features\n",
      "MSZoning has 5 unique features\n",
      "LotFrontage has 369 unique features\n",
      "LotArea has 1073 unique features\n",
      "Street has 2 unique features\n",
      "Alley has 3 unique features\n",
      "LotShape has 4 unique features\n",
      "LandContour has 4 unique features\n",
      "Utilities has 2 unique features\n",
      "LotConfig has 5 unique features\n",
      "LandSlope has 3 unique features\n",
      "Neighborhood has 25 unique features\n",
      "Condition1 has 9 unique features\n",
      "Condition2 has 8 unique features\n",
      "BldgType has 5 unique features\n",
      "HouseStyle has 8 unique features\n",
      "OverallQual has 10 unique features\n",
      "OverallCond has 9 unique features\n",
      "YearBuilt has 112 unique features\n",
      "YearRemodAdd has 61 unique features\n",
      "RoofStyle has 6 unique features\n",
      "RoofMatl has 8 unique features\n",
      "Exterior1st has 15 unique features\n",
      "Exterior2nd has 16 unique features\n",
      "MasVnrType has 5 unique features\n",
      "MasVnrArea has 335 unique features\n",
      "ExterQual has 4 unique features\n",
      "ExterCond has 5 unique features\n",
      "Foundation has 6 unique features\n",
      "BsmtQual has 5 unique features\n",
      "BsmtCond has 5 unique features\n",
      "BsmtExposure has 5 unique features\n",
      "BsmtFinType1 has 7 unique features\n",
      "BsmtFinSF1 has 637 unique features\n",
      "BsmtFinType2 has 7 unique features\n",
      "BsmtFinSF2 has 144 unique features\n",
      "BsmtUnfSF has 780 unique features\n",
      "TotalBsmtSF has 721 unique features\n",
      "Heating has 6 unique features\n",
      "HeatingQC has 5 unique features\n",
      "CentralAir has 2 unique features\n",
      "Electrical has 6 unique features\n",
      "1stFlrSF has 753 unique features\n",
      "2ndFlrSF has 417 unique features\n",
      "LowQualFinSF has 24 unique features\n",
      "GrLivArea has 861 unique features\n",
      "BsmtFullBath has 4 unique features\n",
      "BsmtHalfBath has 3 unique features\n",
      "FullBath has 4 unique features\n",
      "HalfBath has 3 unique features\n",
      "BedroomAbvGr has 8 unique features\n",
      "KitchenAbvGr has 4 unique features\n",
      "KitchenQual has 4 unique features\n",
      "TotRmsAbvGrd has 12 unique features\n",
      "Functional has 7 unique features\n",
      "Fireplaces has 4 unique features\n",
      "FireplaceQu has 6 unique features\n",
      "GarageType has 7 unique features\n",
      "GarageYrBlt has 178 unique features\n",
      "GarageFinish has 4 unique features\n",
      "GarageCars has 5 unique features\n",
      "GarageArea has 441 unique features\n",
      "GarageQual has 6 unique features\n",
      "GarageCond has 6 unique features\n",
      "PavedDrive has 3 unique features\n",
      "WoodDeckSF has 274 unique features\n",
      "OpenPorchSF has 202 unique features\n",
      "EnclosedPorch has 120 unique features\n",
      "3SsnPorch has 20 unique features\n",
      "ScreenPorch has 76 unique features\n",
      "PoolArea has 8 unique features\n",
      "PoolQC has 4 unique features\n",
      "Fence has 5 unique features\n",
      "MiscFeature has 5 unique features\n",
      "MiscVal has 21 unique features\n",
      "MoSold has 12 unique features\n",
      "YrSold has 5 unique features\n",
      "SaleType has 9 unique features\n",
      "SaleCondition has 6 unique features\n"
     ]
    }
   ],
   "source": [
    "for colname, coldata in df_train_explan.iteritems():\n",
    "    print(f'{colname} has', len(set(coldata)), 'unique features')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error for part 4 is: 0.15630755195257634\n"
     ]
    }
   ],
   "source": [
    "# PART 2 QUESTION 4, TRAIN THE MODEL\n",
    "\n",
    "from math import log, sqrt\n",
    "train = [s.strip().split(\",\") for s in open('house-prices-advanced-regression-techniques\\my_train.csv').readlines()]\n",
    "train = train[1:]\n",
    "dev = [s.strip().split(\",\") for s in open('house-prices-advanced-regression-techniques\\my_dev.csv').readlines()]\n",
    "dev = dev[1:]\n",
    "test = [s.strip().split(\",\") for s in open('house-prices-advanced-regression-techniques\\my_test.csv').readlines()]\n",
    "test = test[1:]\n",
    "\n",
    "categorical_features = [1,\t4,\t5,\t6,\t7,\t8,\t9,\t10,\t11,\t12,\t13,\t14,\t19,\t20,\t21,\t22,\t23,\t25,\t26,\t27,\t28,\t29,\t30,\t31,\t33,\t37,\t38,\t39,\t40,\t51,\t53,\t55,\t57,\t60,\t61,\t62,\t72,\t73]\n",
    "numeric_features = [0,\t2,\t3,\t15,\t16,\t17,\t18,\t24,\t32,\t34,\t35,\t36,\t41,\t42,\t43,\t44,\t45,\t46,\t47,\t48,\t49,\t50,\t52,\t54,\t56,\t58,\t59,\t63,\t64,\t65,\t66,\t67,\t68,\t69,\t70,\t71]\n",
    "mapping = {}\n",
    "\n",
    "def binarize(file_list, new = True, sales = True, smart = False):\n",
    "    y = []\n",
    "    new_data = []    \n",
    "    for row in file_list:\n",
    "        new_row = []\n",
    "    \n",
    "        if sales:\n",
    "            y.append(log(float(row[-1])))\n",
    "            end = -1\n",
    "        else:\n",
    "            end = None\n",
    "            \n",
    "        for j, x in enumerate(row[1:end]):\n",
    "            feature = (j, x)\n",
    "            if new:\n",
    "                if feature not in mapping:\n",
    "                    mapping[feature] = len(mapping) # insert a new feature into the index\n",
    "                new_row.append(mapping[feature])\n",
    "            else:\n",
    "                if feature in mapping:\n",
    "                    new_row.append(mapping[feature])\n",
    "        new_data.append(new_row)\n",
    "\n",
    "    bindata = np.zeros((len(new_data),len(mapping)))\n",
    "    for i, row in enumerate(new_data):\n",
    "        for x in row:\n",
    "            bindata[i][x] = 1\n",
    "\n",
    "    return bindata, y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# BINARIZE DATA\n",
    "bindata_train, train_y = binarize(train, new = True)\n",
    "bindata_dev, dev_y = binarize(dev, new = False)\n",
    "bindata_test, test_y = binarize(test, new = False, sales = False)\n",
    "\n",
    "\n",
    "        \n",
    "# CALL LINEAR REGRESSION, FIT MODEL, PREDICT MODEL\n",
    "lm = linear_model.LinearRegression()\n",
    "fit_mod = lm.fit(bindata_train, train_y)\n",
    "pred_y = fit_mod.predict(bindata_dev)\n",
    "print('Mean Squared Error for part 4 is:', sqrt(mean_squared_error(dev_y, pred_y)))\n",
    "        \n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Positive Index: 45 Positive Weight: 0.1502200765778792 Positive Feature: (45, '1710')\n",
      "Neg Index: 551 Neg Weight: -0.195700683334053 Neg Feature: (1, 'C (all)')\n",
      "\n",
      "Positive Index: 299 Positive Weight: 0.1447142007193873 Positive Feature: (16, '9')\n",
      "Neg Index: 35 Neg Weight: -0.18695065472452088 Neg Feature: (35, '0')\n",
      "\n",
      "Positive Index: 8 Positive Weight: 0.12834144476475076 Positive Feature: (8, 'AllPub')\n",
      "Neg Index: 0 Neg Weight: -0.16406225528777732 Neg Feature: (0, '60')\n",
      "\n",
      "Positive Index: 311 Positive Weight: 0.12749464883943112 Positive Feature: (48, '3')\n",
      "Neg Index: 37 Neg Weight: -0.14604398612052277 Neg Feature: (37, '856')\n",
      "\n",
      "Positive Index: 168 Positive Weight: 0.12378709421335773 Positive Feature: (16, '8')\n",
      "Neg Index: 1803 Neg Weight: -0.12858627347290982 Neg Feature: (45, '968')\n",
      "\n",
      "Positive Index: 813 Positive Weight: 0.1205229242608985 Positive Feature: (11, 'StoneBr')\n",
      "Neg Index: 3469 Neg Weight: -0.12769029207771548 Neg Feature: (67, '236')\n",
      "\n",
      "Positive Index: 10 Positive Weight: 0.11893708405244831 Positive Feature: (10, 'Gtl')\n",
      "Neg Index: 3468 Neg Weight: -0.1133367009291251 Neg Feature: (35, '311')\n",
      "\n",
      "Positive Index: 43 Positive Weight: 0.11753997962046643 Positive Feature: (43, '854')\n",
      "Neg Index: 3466 Neg Weight: -0.1133367009291251 Neg Feature: (3, '8281')\n",
      "\n",
      "Positive Index: 34 Positive Weight: 0.11071464385833127 Positive Feature: (34, 'Unf')\n",
      "Neg Index: 789 Neg Weight: -0.10530603522565173 Neg Feature: (0, '160')\n",
      "\n",
      "Positive Index: 4575 Positive Weight: 0.10799250253959562 Positive Feature: (43, '472')\n",
      "Neg Index: 974 Neg Weight: -0.10360596910231745 Neg Feature: (16, '3')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# PART 2 QUESTION 5 TOP 10 AND BOTTOM 10 CURRENTLY NOT PULLING CORRECTLY, LIKELY BECAUSE OF POOR MODEL FIT\n",
    "\n",
    "top_bott = []\n",
    "for i, w in enumerate(fit_mod.coef_):\n",
    "    top_bott.append((i,w))\n",
    "\n",
    "top_bott_sorted = sorted(top_bott, key = lambda x: x[1], reverse = True)\n",
    "\n",
    "    \n",
    "    \n",
    "for i in range(10):\n",
    "    # POSITIVE\n",
    "    for key, vals in mapping.items():\n",
    "        if vals == top_bott_sorted[i][0]:\n",
    "            feat_val = key\n",
    "    print('\\nPositive Index:', top_bott_sorted[i][0], 'Positive Weight:', top_bott_sorted[i][1], 'Positive Feature:', feat_val)\n",
    "    \n",
    "    neg_i = -i -1\n",
    "    # NEGATIVE\n",
    "    for key, vals in mapping.items():\n",
    "        if vals == top_bott_sorted[neg_i][0]:\n",
    "            feat_val = key\n",
    "    print('Neg Index:', top_bott_sorted[neg_i][0], 'Neg Weight:', top_bott_sorted[neg_i][1], 'Neg Feature:', feat_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My fit intercept is: 11.735119279699791\n"
     ]
    }
   ],
   "source": [
    "# PART 2 QUESTION 6, BIAS DIMENSION\n",
    "print('My fit intercept is:', fit_mod.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import exp\n",
    "pred_test = fit_mod.predict(bindata_test)\n",
    "\n",
    "exp_test = exp(1) ** pred_test\n",
    "genIds = np.arange(1461,1461+len(exp_test))\n",
    "\n",
    "df = pd.DataFrame({'Id': genIds, 'SalePrice': exp_test}).set_index('Id')\n",
    "\n",
    "df.to_csv('predict_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3: Smarter Binarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error for section 3 is: 0.12424584328249617\n",
      "My fit intercept is: 10.65856288261491\n"
     ]
    }
   ],
   "source": [
    "#train_copy = [s.strip().split(\",\") for s in open('house-prices-advanced-regression-techniques\\my_train_copy.csv').readlines()]\n",
    "dev_copy = [s.strip().split(\",\") for s in open('house-prices-advanced-regression-techniques\\my_dev_Copy.csv').readlines()]\n",
    "dev_copy = dev_copy[1:]\n",
    "\n",
    "train_copy = [s.strip().split(\",\") for s in open('house-prices-advanced-regression-techniques\\my_train_Copy.csv').readlines()]\n",
    "train_copy = train_copy[1:]\n",
    "\n",
    "test_smart = [s.strip().split(\",\") for s in open(r'house-prices-advanced-regression-techniques\\test_smart.csv').readlines()]\n",
    "test_smart = test_smart[1:]\n",
    "\n",
    "mapping = {}\n",
    "def binarize_smart(file_list, new = True, sales = True):\n",
    "    y = []\n",
    "    new_data = []    \n",
    "    for row in file_list:\n",
    "        new_row = []\n",
    "        row_cat = [row[i+1] for i in categorical_features] # row[1,2,4,7]\n",
    "        if sales:\n",
    "            y.append(log(float(row[-1])))\n",
    "            end = -1\n",
    "        else:\n",
    "            end = None\n",
    "            \n",
    "        for j, x in enumerate(row_cat):\n",
    "            feature = (j, x)\n",
    "            if new:\n",
    "                if feature not in mapping:\n",
    "                    mapping[feature] = len(mapping) # insert a new feature into the index\n",
    "                new_row.append(mapping[feature])\n",
    "            else:\n",
    "                if feature in mapping:\n",
    "                    new_row.append(mapping[feature])\n",
    "        new_data.append(new_row)\n",
    "\n",
    "    bindata = np.zeros((len(new_data),len(mapping)))\n",
    "    for i, row in enumerate(new_data):\n",
    "        for x in row:\n",
    "            bindata[i][x] = 1\n",
    "            \n",
    "            \n",
    "    # CREATE NUMERIC ARRAY\n",
    "    numeric_bindata_smart_train = np.zeros((len(bindata),len(numeric_features)))\n",
    "    for i, row in enumerate(file_list):\n",
    "        numer_row = [row[i+1] for i in numeric_features]\n",
    "        for k, x in enumerate(numer_row):\n",
    "            numeric_bindata_smart_train[i][k] = x \n",
    "    \n",
    "    # CONCAT THE CATEGORICAL AND NUMERIC ARRAYS\n",
    "    full_bindata_smart_train = np.zeros((len(new_data),len(mapping) + len(numeric_features)))\n",
    "\n",
    "    full_bindata_smart_train = np.concatenate((numeric_bindata_smart_train,bindata), axis = 1)\n",
    "            \n",
    "    return full_bindata_smart_train, y\n",
    "\n",
    "# CREATE CATEGORICAL ARRAY\n",
    "bindata_smart_train, smart_train_y = binarize_smart(train_copy, new = True, sales = True)\n",
    "bindata_smart_dev, smart_dev_y = binarize_smart(dev_copy, new = False, sales = True)\n",
    "bindata_smart_test = binarize_smart(test_smart, new = False, sales = False)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "lm2 = linear_model.LinearRegression()\n",
    "fit_mod2 = lm.fit(bindata_smart_train, smart_train_y)\n",
    "pred_y2 = fit_mod.predict(bindata_smart_dev)\n",
    "print('Mean Squared Error for section 3 is:', sqrt(mean_squared_error(smart_dev_y, pred_y2)))\n",
    "\n",
    "# PART 3 QUESTION 6, BIAS DIMENSION\n",
    "print('My fit intercept is:', fit_mod2.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Positive Index: 241 Positive Weight: 0.6118120187965786 Positive Feature: (14, 'CBlock')\n",
      "Neg Index: 275 Neg Weight: -2.338997683125946 Neg Feature: (14, 'CBlock')\n",
      "\n",
      "Positive Index: 215 Positive Weight: 0.46863921346666954 Positive Feature: (13, 'Tar&Grv')\n",
      "Neg Index: 257 Neg Weight: -0.7289277992951565 Neg Feature: (13, 'Tar&Grv')\n",
      "\n",
      "Positive Index: 260 Positive Weight: 0.40100490430077973 Positive Feature: (13, 'Tar&Grv')\n",
      "Neg Index: 271 Neg Weight: -0.3939452474385067 Neg Feature: (13, 'Tar&Grv')\n",
      "\n",
      "Positive Index: 272 Positive Weight: 0.35431883553260773 Positive Feature: (13, 'Tar&Grv')\n",
      "Neg Index: 168 Neg Weight: -0.32776894758913616 Neg Feature: (20, 'Fa')\n",
      "\n",
      "Positive Index: 228 Positive Weight: 0.32509770428142837 Positive Feature: (36, 'Oth')\n",
      "Neg Index: 263 Neg Weight: -0.2259928954964688 Neg Feature: (36, 'Oth')\n",
      "\n",
      "Positive Index: 274 Positive Weight: 0.30501096416332896 Positive Feature: (36, 'Oth')\n",
      "Neg Index: 240 Neg Weight: -0.22251002280815738 Neg Feature: (25, 'Floor')\n",
      "\n",
      "Positive Index: 188 Positive Weight: 0.2744963122231323 Positive Feature: (33, 'Gd')\n",
      "Neg Index: 253 Neg Weight: -0.20661054336342874 Neg Feature: (33, 'Gd')\n",
      "\n",
      "Positive Index: 251 Positive Weight: 0.2709432473867676 Positive Feature: (33, 'Gd')\n",
      "Neg Index: 255 Neg Weight: -0.20042937738382388 Neg Feature: (33, 'Gd')\n",
      "\n",
      "Positive Index: 49 Positive Weight: 0.22931939328591106 Positive Feature: (29, 'TA')\n",
      "Neg Index: 254 Neg Weight: -0.198841328133962 Neg Feature: (29, 'TA')\n",
      "\n",
      "Positive Index: 197 Positive Weight: 0.21134440425989734 Positive Feature: (8, 'RRNe')\n",
      "Neg Index: 179 Neg Weight: -0.1686568879562334 Neg Feature: (13, 'Metal')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# PART 3 QUESTION 5 TOP 10 AND BOTTOM 10 CURRENTLY NOT PULLING CORRECTLY, LIKELY BECAUSE OF POOR MODEL FIT\n",
    "\n",
    "top_bott = []\n",
    "for i, w in enumerate(fit_mod2.coef_):\n",
    "    top_bott.append((i,w))\n",
    "\n",
    "top_bott_sorted = sorted(top_bott, key = lambda x: x[1], reverse = True)\n",
    "\n",
    "    \n",
    "    \n",
    "for i in range(10):\n",
    "    # POSITIVE\n",
    "    for key, vals in mapping.items():\n",
    "        if vals == top_bott_sorted[i][0]:\n",
    "            feat_val = key\n",
    "    print('\\nPositive Index:', top_bott_sorted[i][0], 'Positive Weight:', top_bott_sorted[i][1], 'Positive Feature:', feat_val)\n",
    "    \n",
    "    neg_i = -i -1\n",
    "    # NEGATIVE\n",
    "    for key, vals in mapping.items():\n",
    "        if vals == top_bott_sorted[neg_i][0]:\n",
    "            feat_val = key\n",
    "    print('Neg Index:', top_bott_sorted[neg_i][0], 'Neg Weight:', top_bott_sorted[neg_i][1], 'Neg Feature:', feat_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Expermentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error for ridge alpha 4.0 (naive) is: 0.1391\n",
      "Mean Squared Error for ridge alpha 4.1 (naive) is: 0.1391\n",
      "Mean Squared Error for ridge alpha 4.199999999999999 (naive) is: 0.1391\n",
      "Mean Squared Error for ridge alpha 4.299999999999999 (naive) is: 0.1391\n",
      "Mean Squared Error for ridge alpha 4.399999999999999 (naive) is: 0.1391\n",
      "Mean Squared Error for ridge alpha 4.499999999999998 (naive) is: 0.1391\n",
      "Mean Squared Error for ridge alpha 4.599999999999998 (naive) is: 0.1391\n",
      "Mean Squared Error for ridge alpha 4.6999999999999975 (naive) is: 0.1391\n",
      "Mean Squared Error for ridge alpha 4.799999999999997 (naive) is: 0.139\n",
      "Mean Squared Error for ridge alpha 4.899999999999997 (naive) is: 0.139\n",
      "Mean Squared Error for ridge alpha 4.9999999999999964 (naive) is: 0.139\n",
      "Mean Squared Error for ridge alpha 5.099999999999996 (naive) is: 0.139\n",
      "Mean Squared Error for ridge alpha 5.199999999999996 (naive) is: 0.139\n",
      "Mean Squared Error for ridge alpha 5.299999999999995 (naive) is: 0.139\n",
      "Mean Squared Error for ridge alpha 5.399999999999995 (naive) is: 0.139\n",
      "Mean Squared Error for ridge alpha 5.499999999999995 (naive) is: 0.139\n",
      "Mean Squared Error for ridge alpha 5.599999999999994 (naive) is: 0.139\n",
      "Mean Squared Error for ridge alpha 5.699999999999994 (naive) is: 0.139\n",
      "Mean Squared Error for ridge alpha 5.799999999999994 (naive) is: 0.139\n",
      "Mean Squared Error for ridge alpha 5.899999999999993 (naive) is: 0.139\n"
     ]
    }
   ],
   "source": [
    "# RIDGE REGRESSION NAIVE\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "for i in np.arange(4,6,0.1):\n",
    "    clf = Ridge(alpha=i)\n",
    "    fit_ridge_naive = clf.fit(bindata_train, train_y)\n",
    "\n",
    "    #fit_mod = lm.fit\n",
    "    pred_y = fit_ridge_naive.predict(bindata_dev)\n",
    "    print(f'Mean Squared Error for ridge alpha {i} (naive) is:', round(sqrt(mean_squared_error(dev_y, pred_y)),4))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error for ridge alpha 1.0 (naive) is: 0.1275\n",
      "Mean Squared Error for ridge alpha 1.5 (naive) is: 0.1279\n",
      "Mean Squared Error for ridge alpha 2.0 (naive) is: 0.1281\n",
      "Mean Squared Error for ridge alpha 2.5 (naive) is: 0.1282\n",
      "Mean Squared Error for ridge alpha 3.0 (naive) is: 0.1282\n",
      "Mean Squared Error for ridge alpha 3.5 (naive) is: 0.1282\n",
      "Mean Squared Error for ridge alpha 4.0 (naive) is: 0.1282\n",
      "Mean Squared Error for ridge alpha 4.5 (naive) is: 0.1282\n",
      "Mean Squared Error for ridge alpha 5.0 (naive) is: 0.1282\n",
      "Mean Squared Error for ridge alpha 5.5 (naive) is: 0.1281\n"
     ]
    }
   ],
   "source": [
    "# RIDGE SMART\n",
    "for i in np.arange(1,6,0.5):\n",
    "    clf = Ridge(alpha=i)\n",
    "    fit_ridge_smart = clf.fit(bindata_smart_train, smart_train_y)\n",
    "\n",
    "    #fit_mod = lm.fit\n",
    "    pred_y_ridge = fit_ridge_smart.predict(bindata_smart_dev)\n",
    "    print(f'Mean Squared Error for ridge alpha {i} (naive) is:', round( sqrt(mean_squared_error(smart_dev_y, pred_y_ridge)),4))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error for lasso alpha 1.0 (naive) is: 0.365\n",
      "Mean Squared Error for lasso alpha 1.5 (naive) is: 0.365\n",
      "Mean Squared Error for lasso alpha 2.0 (naive) is: 0.365\n",
      "Mean Squared Error for lasso alpha 2.5 (naive) is: 0.365\n",
      "Mean Squared Error for lasso alpha 3.0 (naive) is: 0.365\n",
      "Mean Squared Error for lasso alpha 3.5 (naive) is: 0.365\n",
      "Mean Squared Error for lasso alpha 4.0 (naive) is: 0.365\n",
      "Mean Squared Error for lasso alpha 4.5 (naive) is: 0.365\n",
      "Mean Squared Error for lasso alpha 5.0 (naive) is: 0.365\n",
      "Mean Squared Error for lasso alpha 5.5 (naive) is: 0.365\n",
      "Mean Squared Error for lasso alpha 1.0 (smart) is: 0.1593\n",
      "Mean Squared Error for lasso alpha 1.5 (smart) is: 0.1634\n",
      "Mean Squared Error for lasso alpha 2.0 (smart) is: 0.1671\n",
      "Mean Squared Error for lasso alpha 2.5 (smart) is: 0.1712\n",
      "Mean Squared Error for lasso alpha 3.0 (smart) is: 0.1767\n",
      "Mean Squared Error for lasso alpha 3.5 (smart) is: 0.1797\n",
      "Mean Squared Error for lasso alpha 4.0 (smart) is: 0.1805\n",
      "Mean Squared Error for lasso alpha 4.5 (smart) is: 0.181\n",
      "Mean Squared Error for lasso alpha 5.0 (smart) is: 0.1817\n",
      "Mean Squared Error for lasso alpha 5.5 (smart) is: 0.1818\n"
     ]
    }
   ],
   "source": [
    "# Try anything else Part 4 question 5\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "for i in np.arange(1,6,0.5):\n",
    "    lm_lasso = linear_model.LinearRegression()\n",
    "    clf = Lasso(alpha=i)\n",
    "    fit_lasso_naive = clf.fit(bindata_train, train_y)\n",
    "\n",
    "    #fit_mod = lm.fit\n",
    "    pred_y = fit_lasso_naive.predict(bindata_dev)\n",
    "    print(f'Mean Squared Error for lasso alpha {i} (naive) is:', round(sqrt(mean_squared_error(dev_y, pred_y)),4))\n",
    "    \n",
    "    \n",
    "for i in np.arange(1,6,0.5):\n",
    "    lm_lasso = linear_model.LinearRegression()\n",
    "    clf = Lasso(alpha=i)\n",
    "    fit_lasso_naive = clf.fit(bindata_smart_train, smart_train_y)\n",
    "\n",
    "    #fit_mod = lm.fit\n",
    "    pred_y_ridge = fit_lasso_naive.predict(bindata_smart_dev)\n",
    "    print(f'Mean Squared Error for lasso alpha {i} (smart) is:', round( sqrt(mean_squared_error(smart_dev_y, pred_y_ridge)),4))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import exp\n",
    "pred_test = fit_mod2.predict(bindata_smart_test[0])\n",
    "\n",
    "exp_test = exp(1) ** pred_test\n",
    "genIds = np.arange(1461,1461+len(exp_test))\n",
    "\n",
    "df = pd.DataFrame({'Id': genIds, 'SalePrice': exp_test}).set_index('Id')\n",
    "\n",
    "df.to_csv('predict_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   20.,    80., 11622., ...,     0.,     0.,     0.],\n",
       "       [   20.,    81., 14267., ...,     0.,     0.,     0.],\n",
       "       [   60.,    74., 13830., ...,     0.,     0.,     0.],\n",
       "       ...,\n",
       "       [   20.,   160., 20000., ...,     0.,     0.,     0.],\n",
       "       [   85.,    62., 10441., ...,     0.,     0.,     0.],\n",
       "       [   60.,    74.,  9627., ...,     0.,     0.,     0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
