{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pprint\n",
    "from collections import defaultdict, Counter\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV text file\n",
    "dev = [s.strip().split(\", \") for s in open('hw1-data/income.dev.txt').readlines()]\n",
    "\n",
    "train = [s.strip().split(\", \") for s in open('hw1-data/income.train.txt').readlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "These values make sence for yearly salaries in the 90s. According to google, median salary in the 90s was around 20,000 dollars so 25\\% of people around \\$50,000 makes sence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Positive Percent is: 1251 of 5000 or 0.2502\n",
      "Dev Positive Percent is: 236 of 1000 or 0.236\n"
     ]
    }
   ],
   "source": [
    "#!cat income.train.txt.5k | sort -nk1 | head -1\n",
    "\n",
    "train_pos,dev_pos = 0,0\n",
    "train_tot, dev_tot = 0,0\n",
    "\n",
    "for row in train:\n",
    "    train_tot += 1\n",
    "    if(row[-1]) == '>50K':\n",
    "        train_pos += 1\n",
    "        \n",
    "print('Train Positive Percent is:', train_pos, 'of', train_tot, 'or', train_pos/train_tot)\n",
    "        \n",
    "        \n",
    "for row in dev:\n",
    "    dev_tot += 1\n",
    "    if(row[-1]) == '>50K':\n",
    "        dev_pos += 1\n",
    "\n",
    "print('Dev Positive Percent is:', dev_pos, 'of', dev_tot, 'or', dev_pos/dev_tot)\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "Q: What are the youngest and oldest ages in the training set? What are the least and most amounts of hours per week do people in this set work? Hint: cat income.train.txt.5k | sort -nk1 | head -1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min Hours 1 min age 17\n",
      "Max Hours 99 max age 90\n"
     ]
    }
   ],
   "source": [
    "min_age = 100\n",
    "max_age = 0\n",
    "min_hours = 100\n",
    "max_hours = 0\n",
    "\n",
    "\n",
    "for row in train:\n",
    "    if int(row[0]) < min_age:\n",
    "        min_age = int(row[0])\n",
    "    if int(row[0]) > max_age:\n",
    "        max_age = int(row[0])\n",
    "    if int(row[-3]) < min_hours:\n",
    "        min_hours = int(row[-3])\n",
    "    if int(row[-3]) > max_hours:\n",
    "        max_hours = int(row[-3])\n",
    "        \n",
    "        \n",
    "print('Min Hours', min_hours, 'min age', min_age)\n",
    "print('Max Hours', max_hours, 'max age', max_age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "Q: How many features do you have in total (i.e., the dimensionality)? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many features do you have in total?\n",
    "mapping = {}\n",
    "new_data = []\n",
    "\n",
    "#BINARIZE DEV\n",
    "for row in dev:\n",
    "    new_row = []\n",
    "    cleanRow = row[1:7] + row[8:9] \n",
    "    for j, x in enumerate(cleanRow):\n",
    "        feature = (j, x)\n",
    "        if feature not in mapping:\n",
    "            mapping[feature] = len(mapping) # insert a new feature into the index\n",
    "        new_row.append(mapping[feature])\n",
    "    new_data.append(new_row)\n",
    "    \n",
    "bindata_dev = np.zeros((1000,len(mapping)))\n",
    "bindata_dev\n",
    "for i, row in enumerate(new_data):\n",
    "    for x in row:\n",
    "        bindata_dev[i][x] = 1\n",
    "        \n",
    "bindata_dev = np.zeros((1000,92))\n",
    "\n",
    "for i, row in enumerate(new_data):\n",
    "    for x in row:\n",
    "        bindata_dev[i][x] = 1\n",
    "\n",
    "        \n",
    "new_data_train = []\n",
    "\n",
    "#BINARIZE TRAIN\n",
    "for row_train in train:\n",
    "    new_row_train = []\n",
    "    cleanRow_train = row_train[1:7] + row_train[8:9] \n",
    "    for j_train, x_train in enumerate(cleanRow_train):\n",
    "        feature_train = (j_train,x_train)\n",
    "        if feature_train not in mapping:\n",
    "            mapping[feature_train] = len(mapping)\n",
    "        new_row_train.append(mapping[feature_train])\n",
    "    new_data_train.append(new_row_train)\n",
    "    \n",
    "bindata_train = np.zeros((5000,92))\n",
    "\n",
    "for i, row_t in enumerate(new_data_train):\n",
    "    for x_t in row_t:\n",
    "        bindata_train[i][x_t] = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART TWO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "Q: Find the five (5) people closest to the last person (in Euclidean distance) in dev, and report their distances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Original Person: \n",
      " ['58', 'Private', 'HS-grad', 'Widowed', 'Adm-clerical', 'White', 'Female', '40', 'United-States', '<=50K']\n",
      "\n",
      "Index: 681 e-distance: 0.0324 \n",
      "person: ['30', 'Private', 'HS-grad', 'Widowed', 'Adm-clerical', 'White', 'Female', '40', 'United-States', '<=50K']\n",
      "\n",
      "Index: 1010 e-distance: 0.4624000000000001 \n",
      "person: ['55', 'Private', 'HS-grad', 'Widowed', 'Adm-clerical', 'White', 'Female', '40', 'United-States', '<=50K']\n",
      "\n",
      "Index: 3680 e-distance: 0.4736000000000001 \n",
      "person: ['49', 'Private', 'HS-grad', 'Widowed', 'Adm-clerical', 'White', 'Female', '20', 'United-States', '<=50K']\n",
      "\n",
      "Index: 3769 e-distance: 0.6152 \n",
      "person: ['58', 'Private', 'HS-grad', 'Widowed', 'Adm-clerical', 'White', 'Female', '27', 'United-States', '<=50K']\n",
      "\n",
      "Index: 3698 e-distance: 0.7376 \n",
      "person: ['59', 'Private', 'HS-grad', 'Widowed', 'Adm-clerical', 'White', 'Female', '60', 'United-States', '<=50K']\n",
      "\n",
      "Index: 681 manhat-distance: 16.559999999999985 \n",
      "person: ['30', 'Private', 'HS-grad', 'Widowed', 'Adm-clerical', 'White', 'Female', '40', 'United-States', '<=50K']\n",
      "\n",
      "Index: 1010 manhat-distance: 62.55999999999998 \n",
      "person: ['55', 'Private', 'HS-grad', 'Widowed', 'Adm-clerical', 'White', 'Female', '40', 'United-States', '<=50K']\n",
      "\n",
      "Index: 3680 manhat-distance: 88.3199999999999 \n",
      "person: ['49', 'Private', 'HS-grad', 'Widowed', 'Adm-clerical', 'White', 'Female', '20', 'United-States', '<=50K']\n",
      "\n",
      "Index: 3769 manhat-distance: 92.0 \n",
      "person: ['58', 'Private', 'HS-grad', 'Widowed', 'Adm-clerical', 'White', 'Female', '27', 'United-States', '<=50K']\n",
      "\n",
      "Index: 3698 manhat-distance: 106.71999999999979 \n",
      "person: ['59', 'Private', 'HS-grad', 'Widowed', 'Adm-clerical', 'White', 'Female', '60', 'United-States', '<=50K']\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "\n",
    "euclid_list = []\n",
    "manhat_list = []\n",
    "\n",
    "personIndex = -1\n",
    "\n",
    "lastPerson = bindata_dev[personIndex]\n",
    "\n",
    "print(lastPerson)\n",
    "#euclid_Dist = np.linalg.norm((bindata_train - lastPerson), axis = 1)    \n",
    "\n",
    "for i,row in enumerate(bindata_train):\n",
    "    euclid_list.append(np.sqrt(sum((row - lastPerson)**2)) + ((int(train[i][0]) - int(train[personIndex][0]))/50)**2 + ((int(train[i][7]) - int(train[personIndex][7]))/50)**2)\n",
    "    manhat_list.append(sum(abs(row - lastPerson) + abs((int(train[i][0]) - int(train[personIndex][0]))/50) + abs((int(train[i][7]) - int(train[personIndex][7]))/50)))\n",
    "    \n",
    "min_euclid = np.argpartition(euclid_list,5)[:5]\n",
    "min_manhat = np.argpartition(manhat_list,5)[:5]\n",
    "\n",
    "\n",
    "print('Original Person: \\n', dev[personIndex])\n",
    "for i,index in enumerate(min_euclid):    \n",
    "    print(\"\\nIndex:\", index, \"e-distance:\", euclid_list[index], \"\\nperson:\", train[index])\n",
    "                       \n",
    "for i in min_euclid:    \n",
    "    print(\"\\nIndex:\", i, \"manhat-distance:\", manhat_list[i], \"\\nperson:\", train[i])\n",
    "                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "Q: Redo the above using Manhattan distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Index: 681 manhat-distance: 16.559999999999985 \n",
      "person: ['30', 'Private', 'HS-grad', 'Widowed', 'Adm-clerical', 'White', 'Female', '40', 'United-States', '<=50K']\n",
      "\n",
      "Index: 1010 manhat-distance: 62.55999999999998 \n",
      "person: ['55', 'Private', 'HS-grad', 'Widowed', 'Adm-clerical', 'White', 'Female', '40', 'United-States', '<=50K']\n",
      "\n",
      "Index: 3680 manhat-distance: 88.3199999999999 \n",
      "person: ['49', 'Private', 'HS-grad', 'Widowed', 'Adm-clerical', 'White', 'Female', '20', 'United-States', '<=50K']\n",
      "\n",
      "Index: 3769 manhat-distance: 92.0 \n",
      "person: ['58', 'Private', 'HS-grad', 'Widowed', 'Adm-clerical', 'White', 'Female', '27', 'United-States', '<=50K']\n",
      "\n",
      "Index: 3698 manhat-distance: 106.71999999999979 \n",
      "person: ['59', 'Private', 'HS-grad', 'Widowed', 'Adm-clerical', 'White', 'Female', '60', 'United-States', '<=50K']\n"
     ]
    }
   ],
   "source": [
    "for i in min_euclid:    \n",
    "    print(\"\\nIndex:\", i, \"manhat-distance:\", manhat_list[i], \"\\nperson:\", train[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "Q: What are the 5-NN predictions for this person (Euclidean and Manhattan)? Are these predictions correct?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both Manhatan and Euclidean methods predict this person to earn <=50k. This is correct.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "Q: Redo all the above using 9-NN (i.e., find top-9 people closest to this person first)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Person: \n",
      " ['58', 'Private', 'HS-grad', 'Widowed', 'Adm-clerical', 'White', 'Female', '40', 'United-States', '<=50K']\n",
      "\n",
      "Index: 681 e-distance: 0.0324 \n",
      "person: ['30', 'Private', 'HS-grad', 'Widowed', 'Adm-clerical', 'White', 'Female', '40', 'United-States', '<=50K']\n",
      "\n",
      "Index: 1010 e-distance: 0.4624000000000001 \n",
      "person: ['55', 'Private', 'HS-grad', 'Widowed', 'Adm-clerical', 'White', 'Female', '40', 'United-States', '<=50K']\n",
      "\n",
      "Index: 3680 e-distance: 0.4736000000000001 \n",
      "person: ['49', 'Private', 'HS-grad', 'Widowed', 'Adm-clerical', 'White', 'Female', '20', 'United-States', '<=50K']\n",
      "\n",
      "Index: 1713 e-distance: 0.81 \n",
      "person: ['66', 'Private', 'HS-grad', 'Widowed', 'Adm-clerical', 'White', 'Female', '40', 'United-States', '<=50K']\n",
      "\n",
      "Index: 3698 e-distance: 0.7376 \n",
      "person: ['59', 'Private', 'HS-grad', 'Widowed', 'Adm-clerical', 'White', 'Female', '60', 'United-States', '<=50K']\n",
      "\n",
      "Index: 3769 e-distance: 0.6152 \n",
      "person: ['58', 'Private', 'HS-grad', 'Widowed', 'Adm-clerical', 'White', 'Female', '27', 'United-States', '<=50K']\n",
      "\n",
      "Index: 2003 e-distance: 0.9236 \n",
      "person: ['68', 'Private', 'HS-grad', 'Widowed', 'Adm-clerical', 'White', 'Female', '30', 'United-States', '<=50K']\n",
      "\n",
      "Index: 2450 e-distance: 1.1664 \n",
      "person: ['75', 'Private', 'HS-grad', 'Widowed', 'Adm-clerical', 'White', 'Female', '40', 'United-States', '<=50K']\n",
      "\n",
      "Index: 3510 e-distance: 1.414613562373095 \n",
      "person: ['20', 'Private', 'HS-grad', 'Married-civ-spouse', 'Adm-clerical', 'White', 'Female', '40', 'United-States', '<=50K']\n",
      "\n",
      "Index: 681 manhat-distance: 16.559999999999985 \n",
      "person: ['30', 'Private', 'HS-grad', 'Widowed', 'Adm-clerical', 'White', 'Female', '40', 'United-States', '<=50K']\n",
      "\n",
      "Index: 1010 manhat-distance: 62.55999999999998 \n",
      "person: ['55', 'Private', 'HS-grad', 'Widowed', 'Adm-clerical', 'White', 'Female', '40', 'United-States', '<=50K']\n",
      "\n",
      "Index: 3680 manhat-distance: 88.3199999999999 \n",
      "person: ['49', 'Private', 'HS-grad', 'Widowed', 'Adm-clerical', 'White', 'Female', '20', 'United-States', '<=50K']\n",
      "\n",
      "Index: 1713 manhat-distance: 82.80000000000004 \n",
      "person: ['66', 'Private', 'HS-grad', 'Widowed', 'Adm-clerical', 'White', 'Female', '40', 'United-States', '<=50K']\n",
      "\n",
      "Index: 3698 manhat-distance: 106.71999999999979 \n",
      "person: ['59', 'Private', 'HS-grad', 'Widowed', 'Adm-clerical', 'White', 'Female', '60', 'United-States', '<=50K']\n",
      "\n",
      "Index: 3769 manhat-distance: 92.0 \n",
      "person: ['58', 'Private', 'HS-grad', 'Widowed', 'Adm-clerical', 'White', 'Female', '27', 'United-States', '<=50K']\n",
      "\n",
      "Index: 2003 manhat-distance: 104.88000000000004 \n",
      "person: ['68', 'Private', 'HS-grad', 'Widowed', 'Adm-clerical', 'White', 'Female', '30', 'United-States', '<=50K']\n",
      "\n",
      "Index: 2450 manhat-distance: 99.35999999999987 \n",
      "person: ['75', 'Private', 'HS-grad', 'Widowed', 'Adm-clerical', 'White', 'Female', '40', 'United-States', '<=50K']\n",
      "\n",
      "Index: 3510 manhat-distance: 3.8400000000000016 \n",
      "person: ['20', 'Private', 'HS-grad', 'Married-civ-spouse', 'Adm-clerical', 'White', 'Female', '40', 'United-States', '<=50K']\n"
     ]
    }
   ],
   "source": [
    "min_euclid = np.argpartition(euclid_list,9)[:9]\n",
    "min_manhat = np.argpartition(manhat_list,9)[:9]\n",
    "\n",
    "\n",
    "print('Original Person: \\n', dev[personIndex])\n",
    "for i,index in enumerate(min_euclid):    \n",
    "    print(\"\\nIndex:\", index, \"e-distance:\", euclid_list[index], \"\\nperson:\", train[index])\n",
    "                       \n",
    "for i in min_euclid:    \n",
    "    print(\"\\nIndex:\", i, \"manhat-distance:\", manhat_list[i], \"\\nperson:\", train[i])                  \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both Euclidean and Manhatan distances predict salary as <=50k which is correct.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART THREE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K NEAREST NEIGHBOR CLASSIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Implement the basic k-NN classifier (with the default Euclidean distance)\n",
    "Q: Is there any work in training after finishing the feature map?\n",
    "\n",
    "    No, we are not trainging in this example\n",
    "\n",
    "\n",
    "Q: What’s the time complexity of k-NN to test one example (dimensionality d, size of training set |D|)?  \n",
    "    \n",
    "    1. Calculating the distance between each person: O(D) * d (all people)\n",
    "    2. Sort the algorithm: O(D^2)\n",
    "    3. Time to check the top matches: k\n",
    "    4. Overall time complexity: O(D) * d + D^2 + k\n",
    "    \n",
    "\n",
    "\n",
    "Q: Do you really need to sort the distances first and then choose the top k? Hint: there is a faster way to choose top k without sorting\n",
    "\n",
    "    I belive it would be faster to search the list of distances for minimum and remove them without replacement. This time complexity would simply be D*k.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duration is: -15.797553777694702 seconds.\n",
      "k = 33 train_err 18.24% (+:19.38%) dev_err 15.70% (+:18.50%)\n"
     ]
    }
   ],
   "source": [
    "def dev_error(k):\n",
    "    string = []\n",
    "    for k in k:\n",
    "        correct = 0\n",
    "        total_predicted_positives = 0\n",
    "        for i, entry in enumerate(bindata_dev): # enumerate each person in the dev set\n",
    "            dists = np.linalg.norm((bindata_train - entry), axis=1) # calculate Euclidean distances\n",
    "            topk_indices = np.argsort(dists)[:k] # sort distances and return indices\n",
    "            num_positives = 0\n",
    "            for person_idx in topk_indices:\n",
    "                if train[person_idx][-1] == \">50K\".upper():\n",
    "                    num_positives += 1\n",
    "            if num_positives > k/2:\n",
    "                predicted_label = \">50K\".upper()\n",
    "                total_predicted_positives += 1\n",
    "            else:\n",
    "                predicted_label = \"<=50K\".upper()\n",
    "            if predicted_label == dev[i][-1]:\n",
    "                correct += 1\n",
    "\n",
    "        error = 1 - correct / len(bindata_dev)\n",
    "        positive_rate = total_predicted_positives / len(bindata_dev)\n",
    "\n",
    "        string.append('dev_err {:.2%}'.format(error) + ' (+:{:.2%})'.format(positive_rate) )\n",
    "    return string\n",
    "        \n",
    "# TRAIN ERROR\n",
    "def train_error(k):\n",
    "    string = []\n",
    "    for k in k:\n",
    "        correct = 0\n",
    "        total_predicted_positives = 0\n",
    "        for i, entry in enumerate(bindata_train): # enumerate each person in the dev set\n",
    "            dists = np.linalg.norm((bindata_train - entry), axis=1) # calculate Euclidean distances\n",
    "            topk_indices = np.argsort(dists)[:k] # sort distances and return indices\n",
    "            num_positives = 0\n",
    "            for person_idx in topk_indices:\n",
    "                if train[person_idx][-1] == \">50K\".upper():\n",
    "                    num_positives += 1\n",
    "            if num_positives > k/2:\n",
    "                predicted_label = \">50K\".upper()\n",
    "                total_predicted_positives += 1\n",
    "            else:\n",
    "                predicted_label = \"<=50K\".upper()\n",
    "            if predicted_label == train[i][-1]:\n",
    "                correct += 1\n",
    "\n",
    "        error = 1 - correct / len(bindata_train)\n",
    "        positive_rate = total_predicted_positives / len(bindata_train)\n",
    "\n",
    "        string.append('train_err {:.2%}'.format(error) + ' (+:{:.2%})'.format(positive_rate) )\n",
    "    return string\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "time1 = time.time()\n",
    "#k = [1, 3, 5, 7, 9, 99, 999, 9999]\n",
    "k = [33]\n",
    "train_err = train_error(k)\n",
    "dev_err = dev_error(k)\n",
    "\n",
    "time2 = time.time()\n",
    "print('duration is:', time1-time2, 'seconds.')\n",
    "for i,k in enumerate(k):\n",
    "    print('k =', k, train_err[i], dev_err[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dev_error_manhat(k):\n",
    "    string = []\n",
    "    for k in k:\n",
    "        correct = 0\n",
    "        total_predicted_positives = 0\n",
    "        for i, entry in enumerate(bindata_dev): # enumerate each person in the dev set\n",
    "            dists = np.sum(np.abs(bindata_train - entry), axis=1) # calculate Euclidean distances\n",
    "            topk_indices = np.argsort(dists)[:k] # sort distances and return indices\n",
    "            num_positives = 0\n",
    "            for person_idx in topk_indices:\n",
    "                if train[person_idx][-1] == \">50K\".upper():\n",
    "                    num_positives += 1\n",
    "            if num_positives > k/2:\n",
    "                predicted_label = \">50K\".upper()\n",
    "                total_predicted_positives += 1\n",
    "            else:\n",
    "                predicted_label = \"<=50K\".upper()\n",
    "            if predicted_label == dev[i][-1]:\n",
    "                correct += 1\n",
    "\n",
    "        error = 1 - correct / len(bindata_dev)\n",
    "        positive_rate = total_predicted_positives / len(bindata_dev)\n",
    "\n",
    "        string.append('dev_err {:.2%}'.format(error) + ' (+:{:.2%})'.format(positive_rate) )\n",
    "    return string\n",
    "        \n",
    "# TRAIN ERROR\n",
    "def train_error_manhat(k):\n",
    "    string = []\n",
    "    for k in k:\n",
    "        correct = 0\n",
    "        total_predicted_positives = 0\n",
    "        for i, entry in enumerate(bindata_train): # enumerate each person in the dev set\n",
    "            dists = np.sum(np.abs(bindata_train - entry), axis=1) # calculate Euclidean distances\n",
    "            topk_indices = np.argsort(dists)[:k] # sort distances and return indices\n",
    "            num_positives = 0\n",
    "            for person_idx in topk_indices:\n",
    "                if train[person_idx][-1] == \">50K\".upper():\n",
    "                    num_positives += 1\n",
    "            if num_positives > k/2:\n",
    "                predicted_label = \">50K\".upper()\n",
    "                total_predicted_positives += 1\n",
    "            else:\n",
    "                predicted_label = \"<=50K\".upper()\n",
    "            if predicted_label == train[i][-1]:\n",
    "                correct += 1\n",
    "\n",
    "        error = 1 - correct / len(bindata_train)\n",
    "        positive_rate = total_predicted_positives / len(bindata_train)\n",
    "\n",
    "        string.append('train_err {:.2%}'.format(error) + ' (+:{:.2%})'.format(positive_rate) )\n",
    "    return string\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "time1 = time.time()\n",
    "  \n",
    "        \n",
    "        \n",
    "k = [1, 3, 5, 7, 9, 99, 999, 9999]\n",
    "train_err = train_error_manhat(k)\n",
    "dev_err = dev_error_manhat(k)\n",
    "\n",
    "time2 = time.time()\n",
    "print('duration is:', time1-time2, 'seconds.')\n",
    "\n",
    "for i,k in enumerate(k):\n",
    "    print('k =', k, train_err[i], dev_err[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The best error rate on dev is between k = 9 and k = 99 (~16%). I plotted a few more than instructed to bridge the gap between 9 and 99 and found that k = 33 with an error rate of 15.70% had the lowest error rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4\n",
    "\n",
    "Now try more k’s and take your best model and run it on the semi-blind test data, and produce income.test.predicted, which has the same format as the training and dev files. \n",
    "\n",
    "## Q: At which k and with which distance did you achieve the best dev results? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binarize blind data\n",
    "\n",
    "blind = [s.strip().split(\", \") for s in open('hw1-data/income_blind.txt').readlines()]\n",
    "\n",
    "new_data = []\n",
    "\n",
    "#BINARIZE Blind\n",
    "for row in blind:\n",
    "    new_row = []\n",
    "    cleanRow = row[1:7] + row[8:9] \n",
    "    for j, x in enumerate(cleanRow):\n",
    "        feature = (j, x)\n",
    "        if feature not in mapping:\n",
    "            mapping[feature] = len(mapping) # insert a new feature into the index\n",
    "        new_row.append(mapping[feature])\n",
    "    new_data.append(new_row)\n",
    "    \n",
    "bindata_blind = np.zeros((1000,len(mapping)))\n",
    "bindata_blind\n",
    "\n",
    "for i, row in enumerate(new_data):\n",
    "    for x in row:\n",
    "        bindata_blind[i][x] = 1\n",
    "        \n",
    "bindata_blind = np.zeros((1000,92))\n",
    "\n",
    "for i, row in enumerate(new_data):\n",
    "    for x in row:\n",
    "        bindata_blind[i][x] = 1\n",
    "\n",
    "        \n",
    "        \n",
    "len(bindata_blind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the best results were from euclidean at k = 33\n",
    "\n",
    "#Search train for match from blind. Return k nearest predictions\n",
    "\n",
    "def blind_predict(k): \n",
    "    predicted_labels = []\n",
    "    #string = []\n",
    "    error = 0\n",
    "    positive_rate = 0\n",
    "    for i, entry in enumerate(bindata_blind): # enumerate each person in the blind set\n",
    "        dists = np.linalg.norm((bindata_train - entry), axis=1) # calculate Euclidean distances to training data\n",
    "        topk_indices = np.argsort(dists)[:k] # sort distances and return indices\n",
    "        num_positives = 0\n",
    "        for person_idx in topk_indices:\n",
    "            if train[person_idx][-1] == \">50K\".upper():\n",
    "                num_positives += 1\n",
    "        if num_positives > k/2:\n",
    "            predicted_labels.append(\">50K\")\n",
    "        else:\n",
    "            predicted_labels.append(\"<=50K\")\n",
    "            \n",
    "    #string.append('dev_err {:.2%}'.format(error) + ' (+:{:.2%})'.format(positive_rate) )\n",
    "\n",
    "    return predicted_labels\n",
    "\n",
    "labels = blind_predict(33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = 0\n",
    "neg = 0\n",
    "row = []\n",
    "blind = [s.strip().split(\", \") for s in open('hw1-data/income_blind.txt').readlines()]\n",
    "# Concat blind and label\n",
    "with open('income.test.predicted.txt', 'w') as file:\n",
    "    for i,row in enumerate(blind):\n",
    "        line = row\n",
    "        line.append(labels[i])\n",
    "        file.write(', '.join(line) + '\\n')\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = []\n",
    "\n",
    "#BINARIZE SUPER DEV\n",
    "for row in dev:\n",
    "    new_row = [] \n",
    "    for j, x in enumerate(row):\n",
    "        feature = (j, x)\n",
    "        if feature not in mapping:\n",
    "            mapping[feature] = len(mapping) # insert a new feature into the index\n",
    "        new_row.append(mapping[feature])\n",
    "    new_data.append(new_row)\n",
    "    \n",
    "bindata_superdev = np.zeros((1000,len(mapping)))\n",
    "\n",
    "\n",
    "for i, row in enumerate(new_data):\n",
    "    for x in row:\n",
    "        bindata_superdev[i][x] = 1\n",
    "        \n",
    "\n",
    "\n",
    "new_data = []\n",
    "\n",
    "#BINARIZE SUPER TRAIN\n",
    "for row in train:\n",
    "    new_row = [] \n",
    "    for j, x in enumerate(row):\n",
    "        feature = (j, x)\n",
    "        if feature not in mapping:\n",
    "            mapping[feature] = len(mapping) # insert a new feature into the index\n",
    "        new_row.append(mapping[feature])\n",
    "    new_data.append(new_row)\n",
    "    \n",
    "bindata_supertrain = np.zeros((5000,len(mapping)))\n",
    "\n",
    "\n",
    "for i, row in enumerate(new_data):\n",
    "    for x in row:\n",
    "        bindata_supertrain[i][x] = 1\n",
    "        \n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def big_dev_error(k):\n",
    "    string = []\n",
    "    for k in k:\n",
    "        correct = 0\n",
    "        total_predicted_positives = 0\n",
    "        for i, entry in enumerate(bindata_superdev): # enumerate each person in the dev set\n",
    "            dists = np.linalg.norm((bindata_supertrain - entry), axis=1) # calculate Euclidean distances\n",
    "            topk_indices = np.argsort(dists)[:k] # sort distances and return indices\n",
    "            num_positives = 0\n",
    "            for person_idx in topk_indices:\n",
    "                if train[person_idx][-1] == \">50K\".upper():\n",
    "                    num_positives += 1\n",
    "            if num_positives > k/2:\n",
    "                predicted_label = \">50K\".upper()\n",
    "                total_predicted_positives += 1\n",
    "            else:\n",
    "                predicted_label = \"<=50K\".upper()\n",
    "            if predicted_label == dev[i][-1]:\n",
    "                correct += 1\n",
    "\n",
    "        error = 1 - correct / len(bindata_superdev)\n",
    "        positive_rate = total_predicted_positives / len(bindata_superdev)\n",
    "\n",
    "        string.append('super dev_err {:.2%}'.format(error) + ' (+:{:.2%})'.format(positive_rate) )\n",
    "    return string\n",
    "        \n",
    "def big_train_error(k):\n",
    "    string = []\n",
    "    for k in k:\n",
    "        correct = 0\n",
    "        total_predicted_positives = 0\n",
    "        for i, entry in enumerate(bindata_supertrain): # enumerate each person in the dev set\n",
    "            dists = np.linalg.norm((bindata_supertrain - entry), axis=1) # calculate Euclidean distances\n",
    "            topk_indices = np.argsort(dists)[:k] # sort distances and return indices\n",
    "            num_positives = 0\n",
    "            for person_idx in topk_indices:\n",
    "                if train[person_idx][-1] == \">50K\".upper():\n",
    "                    num_positives += 1\n",
    "            if num_positives > k/2:\n",
    "                predicted_label = \">50K\".upper()\n",
    "                total_predicted_positives += 1\n",
    "            else:\n",
    "                predicted_label = \"<=50K\".upper()\n",
    "            if predicted_label == train[i][-1]:\n",
    "                correct += 1\n",
    "\n",
    "        error = 1 - correct / len(bindata_supertrain)\n",
    "        positive_rate = total_predicted_positives / len(bindata_supertrain)\n",
    "\n",
    "        string.append('super train_err {:.2%}'.format(error) + ' (+:{:.2%})'.format(positive_rate) )\n",
    "    return string\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "time1 = time.time()\n",
    "k = [1, 3, 5, 7, 9, 99, 999, 9999]\n",
    "#k = [33,41]\n",
    "dev_err = big_dev_error(k)\n",
    "train_err = big_train_error(k)\n",
    "\n",
    "time2 = time.time()\n",
    "print('duration is:', time2-time1, 'seconds.')\n",
    "for i,k in enumerate(k):\n",
    "    print('k =', k, train_err[i], dev_err[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
